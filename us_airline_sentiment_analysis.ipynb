{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Et4MiK5WY_8x"
   },
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/crowdflower/twitter-airline-sentiment/version/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1kCygmXxZZaI",
    "outputId": "c5bab6b4-9482-4955-d274-273b187ff617"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 22 17:24:31 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   37C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xUL2dIayZbzC",
    "outputId": "b74686f0-6121-479f-cbad-fe2a082ea894"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/notebooks/twitter_senitment_analysis\n"
     ]
    }
   ],
   "source": [
    "%cd drive/MyDrive/notebooks/twitter_senitment_analysis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3g-hsgQsZy7_",
    "outputId": "dff9b9d8-8921-400a-d51e-b0172c4b0964"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_mrtx_doc2Vec.png   confusion_mrtx_lda.png  topic_10_Data.pkl\n",
      "confusion_mrtx_ensamble.png  confusion_mrtx_use.png  topic_20_Data.pkl\n",
      "confusion_mrtx_grdbst.png    main.ipynb\t\t     Tweets.csv\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9exZZZpIZfDM"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yvOJI25qZsxA",
    "outputId": "4c3346d2-b0f9-48dc-e1d9-3e24efcb310d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                          int64\n",
       "airline_sentiment                object\n",
       "airline_sentiment_confidence    float64\n",
       "negativereason                   object\n",
       "negativereason_confidence       float64\n",
       "airline                          object\n",
       "airline_sentiment_gold           object\n",
       "name                             object\n",
       "negativereason_gold              object\n",
       "retweet_count                     int64\n",
       "text                             object\n",
       "tweet_coord                      object\n",
       "tweet_created                    object\n",
       "tweet_location                   object\n",
       "user_timezone                    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('Tweets.csv')\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "JdwyG9WyZ17v",
    "outputId": "80fac15d-d72e-48d3-abac-366b850eff3d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id  ...               user_timezone\n",
       "0  570306133677760513  ...  Eastern Time (US & Canada)\n",
       "1  570301130888122368  ...  Pacific Time (US & Canada)\n",
       "2  570301083672813571  ...  Central Time (US & Canada)\n",
       "3  570301031407624196  ...  Pacific Time (US & Canada)\n",
       "4  570300817074462722  ...  Pacific Time (US & Canada)\n",
       "\n",
       "[5 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NRpILNMvaDD3"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(data.airline_sentiment)\n",
    "data['categorical_label'] = le.transform(data.airline_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rFIrNdE5pqEr"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import collections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "def text_preprocess(text, tknzr):\n",
    "    FLAGS = re.MULTILINE | re.DOTALL\n",
    "    # Different regex parts for smiley faces\n",
    "    eyes = r\"[8:=;]\"\n",
    "    nose = r\"['`\\-]?\"\n",
    "    # function so code less repetitive\n",
    "    def re_sub(pattern, repl):\n",
    "        return re.sub(pattern, repl, text, flags=FLAGS)\n",
    "    text = re_sub(r\"https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*\", \"<url>\")\n",
    "    text = re_sub(r\"/\",\" / \")\n",
    "    text = re_sub(r\"@\\w+\", \"<user>\")\n",
    "    text = re_sub(r\"{}{}[)dD]+|[)dD]+{}{}\".format(eyes, nose, nose, eyes), \"<smile>\")\n",
    "    text = re_sub(r\"{}{}p+\".format(eyes, nose), \"<lolface>\")\n",
    "    text = re_sub(r\"{}{}\\(+|\\)+{}{}\".format(eyes, nose, nose, eyes), \"<sadface>\")\n",
    "    text = re_sub(r\"{}{}[\\/|l*]\".format(eyes, nose), \"<neutralface>\")\n",
    "    text = re_sub(r\"<3\",\"<heart>\")\n",
    "    text = re_sub(r\"[-+]?[.\\d]*[\\d]+[:,.\\d]*\", \"<number>\")\n",
    "    text = re_sub(r\"([!?.]){2,}\", r\"\\1 <repeat>\")\n",
    "    text = re_sub(r\"\\b(\\S*?)(.)\\2{2,}\\b\", r\"\\1\\2 <elong>\")\n",
    "    text = re_sub(r\"[A-Za-z]+[@#$%^&*()]+[A-Za-z]*\",\"abuse\")\n",
    "    tokens = tknzr.tokenize(text.lower())\n",
    "    return tokens #\" \".join(tokens)\n",
    "tknzr=TweetTokenizer(reduce_len=True, preserve_case=False, strip_handles=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pcK_ive_rxpR"
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "for idx in data.index:\n",
    "  X.append(text_preprocess(data['text'][idx], tknzr))\n",
    "  Y.append(data['categorical_label'][idx])\n",
    "# Train-Test splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)\n",
    "labels = ['Negative','Neutral', 'Positive']  # For further use..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "koT9Z26FsYHT"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# This utility function will be used to evaluate the other models also.\n",
    "def show_performance_data(Y_test, Y_pred, modelname):\n",
    "  tmp_result = classification_report(Y_test, Y_pred, target_names=labels, output_dict=True)\n",
    "  print(classification_report(Y_test, Y_pred, target_names=labels))\n",
    "  cm1 = confusion_matrix(Y_test, Y_pred)\n",
    "  df_cm = pd.DataFrame(cm1, index = [i for i in labels], columns = [i for i in labels])\n",
    "  plt.figure(figsize = (7,5))\n",
    "  sn.heatmap(df_cm, annot=True,cmap='gist_earth_r', fmt='g')\n",
    "  plt.savefig('confusion_mrtx_'+modelname+'.png',bbox_inches = 'tight')\n",
    "  return tmp_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WnaMnguG_2IH"
   },
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qz3NuvEu87Pa"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "# train model\n",
    "model = Word2Vec(X_train, min_count=1)\n",
    "# Helper function\n",
    "def get_w2v_vector(doc):\n",
    "  tmp = []\n",
    "  for w in doc:\n",
    "    try:\n",
    "      tmp.append(model[w])\n",
    "    except:\n",
    "      pass\n",
    "  return np.mean(tmp, axis=0)\n",
    "# Convert training text into vectors \n",
    "train_vectors_w2v = []\n",
    "for doc in X_train:\n",
    "    try:\n",
    "      train_vectors_w2v.append(get_w2v_vector(doc))\n",
    "    except Exception:\n",
    "      print('error...')\n",
    "# Convert Test text into vectors\n",
    "test_vectors_w2v = []\n",
    "for doc in X_test:\n",
    "    try:\n",
    "      test_vectors_w2v.append(get_w2v_vector(doc))\n",
    "    except Exception:\n",
    "      print('error...')\n",
    "cosine_similarities = linear_kernel(train_vectors_w2v, test_vectors_w2v)\n",
    "Y_pred = []\n",
    "for cs in cosine_similarities.T:\n",
    "    idx = cs.argsort()[-1]\n",
    "    Y_pred.append(Y_train[idx])\n",
    "result_word2vec = show_performance_data(Y_test, Y_pred, 'w2v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wbrfAJ7SACEv"
   },
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j2fmEcTFjBAt"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from gensim.corpora import Dictionary\n",
    "import gensim\n",
    "from gensim.matutils import cossim\n",
    "topic = 20\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "dictionary = Dictionary(X_train)\n",
    "train_corpus = [dictionary.doc2bow(doc) for doc in X_train]\n",
    "model = Lda(corpus=train_corpus, id2word=dictionary, num_topics=topic)\n",
    "test_corpus = [dictionary.doc2bow(doc) for doc in X_test]\n",
    "train_x_topics, test_x_topics = [], []\n",
    "# Convert text data into topic vectors\n",
    "for t in train_corpus:\n",
    "  train_x_topics.append(model[t])\n",
    "for t in test_corpus:\n",
    "  test_x_topics.append(model[t])\n",
    "# Prediction\n",
    "Y_pred = []\n",
    "for i in range(len(test_x_topics)):\n",
    "  tst = test_x_topics[i]\n",
    "  sim = [cossim(tst, tr_t) for tr_t in train_x_topics]\n",
    "  idx = np.array(sim).argsort()[-1]\n",
    "  Y_pred.append(Y_train[idx])\n",
    "result_lda = show_performance_data(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P2g9JdLO2PBf"
   },
   "source": [
    "# Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C3oGwFFNvuwF"
   },
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "vec = 100\n",
    "tagged_corpus = [TaggedDocument(d, [i]) for i, d in enumerate(X_train)]\n",
    "model = Doc2Vec(tagged_corpus, vector_size=vec, window=3, dm=1, min_count=1, workers=4)\n",
    "Y_pred = []\n",
    "for a in X_test:\n",
    "  test_doc_vector = model.infer_vector(a)\n",
    "  sims = model.docvecs.most_similar(positive = [test_doc_vector])\n",
    "  Y_pred.append(Y_train[sims[0][0]])\n",
    "result_doc2vec = show_performance_data(Y_test, Y_pred, 'doc2vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pWgcGC9lAGOx"
   },
   "source": [
    "# USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yuLNc3JG5ITF"
   },
   "outputs": [],
   "source": [
    "from absl import logging\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "# Loading USE encoder\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "use_model = hub.load(module_url)\n",
    "print (\"module %s loaded\" % module_url)\n",
    "def get_use_vector(doc):\n",
    "  tmp = use_model(doc)\n",
    "  return np.mean(tmp, axis=0)\n",
    "# Convert text data into vector\n",
    "train_vectors = []\n",
    "for doc in X_train:\n",
    "    try:\n",
    "      train_vectors.append(get_use_vector(doc))\n",
    "    except Exception:\n",
    "      print('error...')\n",
    "test_vectors = []\n",
    "for doc in X_test:\n",
    "    try:\n",
    "      test_vectors.append(get_use_vector(doc))\n",
    "    except Exception:\n",
    "      print('error...')\n",
    "Y_pred = []\n",
    "\n",
    "cosine_similarities = linear_kernel(train_vectors, test_vectors)\n",
    "for cs in cosine_similarities.T:\n",
    "    idx = cs.argsort()[-1]\n",
    "    Y_pred.append(Y_train[idx])\n",
    "cosine_similarities = linear_kernel(train_vectors, test_vectors)\n",
    "result_use = show_performance_data(Y_test, Y_pred, 'use')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3HIdONzQkH4H"
   },
   "source": [
    "# KNN using USE embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dZDqcCZij1QY"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh.fit(train_vectors, Y_train)\n",
    "Y_pred = neigh.predict(test_vectors)\n",
    "result_knn = show_performance_data(Y_test, Y_pred, 'knn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bOFXOzUMj4B3"
   },
   "source": [
    "# Ensamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HEAHf23Nn2ic"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "clf = clf.fit(train_vectors, Y_train)\n",
    "Y_pred = clf.predict(test_vectors)\n",
    "result_rnmdfst = show_performance_data(Y_test, Y_pred, 'rndmfst')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uHz6hqlDpFN7"
   },
   "source": [
    "#GredientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3fyNbBqzpC45"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(n_estimators=15, learning_rate=1.0,max_depth=1, random_state=0).fit(train_vectors, Y_train)\n",
    "Y_pred = clf.predict(test_vectors)\n",
    "result_grdbst = show_performance_data(Y_test, Y_pred, 'grdbst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ata7SeZ1AYim"
   },
   "outputs": [],
   "source": [
    "N = 3\n",
    "results = {'Doc2Vec':result_doc2vec, 'Word2Vec':result_word2vec, 'KNN':result_knn, 'USE':result_use, 'Random Forest':result_rnmdfst, 'Gredient Boost':result_grdbst, 'LDA':result_lda}\n",
    "ind = np.arange(N) \n",
    "width = 0.1\n",
    "p = []\n",
    "clr = ['b','g','r','c','m','k','y']\n",
    "i=0\n",
    "for a,b in results.items():\n",
    "  tmp = [b['Negative']['precision'], b['Neutral']['precision'], b['Positive']['precision']] # replace 'precision' with 'recall' or 'f1-score' for the next two plots.\n",
    "  print(tmp)\n",
    "  p.append(plt.bar(ind+width*i, tmp, width, color = clr[i]))\n",
    "  i+=1\n",
    "plt.xlabel(\"Sentiments\")\n",
    "plt.ylabel('Precision')\n",
    "plt.title(\"Precison comparison of all the models with respect to sentiments\")\n",
    "plt.xticks(ind+width,labels)\n",
    "plt.legend( tuple(p), tuple(results.keys()), loc='upper center', ncol=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FRoDDpweHBDh"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mjqv78Hi_XbH"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "N = 3\n",
    "ind = np.arange(N) \n",
    "width = 0.1\n",
    "p = []\n",
    "clr = ['b','g','r','c','m','k','y']\n",
    "i=0\n",
    "for a,b in results.items():\n",
    "  tmp = [b['Negative']['precision'], b['Neutral']['precision'], b['Positive']['precision']]\n",
    "  print(tmp)\n",
    "  p.append(plt.bar(ind+width*i, tmp, width, color = clr[i]))\n",
    "  i+=1\n",
    "plt.xlabel(\"Sentiments\")\n",
    "plt.ylabel('Precision')\n",
    "plt.title(\"Precison comparison of all the models with respect to sentiments\")\n",
    "plt.xticks(ind+width,labels)\n",
    "plt.legend( tuple(p), tuple(results.keys()), loc='upper center', ncol=2)\n",
    "plt.show()\n",
    "plt.savefig('all_precision.png',bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uLGANh3TDiIs"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "N = 3\n",
    "ind = np.arange(N) \n",
    "width = 0.1\n",
    "  \n",
    "r = []\n",
    "clr = ['b','g','r','c','m','k','y']\n",
    "i=0\n",
    "for a,b in results.items():\n",
    "  tmp = [b['Negative']['recall'], b['Neutral']['recall'], b['Positive']['recall']]\n",
    "  print(tmp)\n",
    "  r.append(plt.bar(ind+width*i, tmp, width, color = clr[i]))\n",
    "  i+=1\n",
    "\n",
    "  \n",
    "plt.xlabel(\"Sentiments\")\n",
    "plt.ylabel('Recall')\n",
    "plt.title(\"Recall comparison of all the models with respect to sentiments\")\n",
    "  \n",
    "plt.xticks(ind+width,labels)\n",
    "plt.legend( tuple(r), tuple(results.keys()), loc='upper center', ncol=2)\n",
    "#plt.show()\n",
    "plt.savefig('all_recall.png',bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BpUn8mtqJXu8"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "N = 3\n",
    "ind = np.arange(N) \n",
    "width = 0.1\n",
    "  \n",
    "f = []\n",
    "clr = ['b','g','r','c','m','k','y']\n",
    "i=0\n",
    "for a,b in results.items():\n",
    "  tmp = [b['Negative']['f1-score'], b['Neutral']['f1-score'], b['Positive']['f1-score']]\n",
    "  print(tmp)\n",
    "  f.append(plt.bar(ind+width*i, tmp, width, color = clr[i]))\n",
    "  i+=1\n",
    "\n",
    "  \n",
    "plt.xlabel(\"Sentiments\")\n",
    "plt.ylabel('F1-score')\n",
    "plt.title(\"F score comparison of all the models with respect to sentiments\")\n",
    "  \n",
    "plt.xticks(ind+width,labels)\n",
    "plt.legend( tuple(f), tuple(results.keys()), loc='upper center', ncol=2)\n",
    "#plt.show()\n",
    "plt.savefig('all_f_score.png',bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9e3FKqjSJrfu"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "N = 3\n",
    "ind = np.arange(N) \n",
    "width = 0.1\n",
    "f = []\n",
    "clr = ['b','g','r','c','m','k','y']\n",
    "i=0\n",
    "for a,b in results.items():\n",
    "  tmp = [b['weighted avg']['precision'], b['weighted avg']['recall'], b['weighted avg']['f1-score']]\n",
    "  print(tmp)\n",
    "  f.append(plt.bar(ind+width*i, tmp, width, color = clr[i]))\n",
    "  i+=1\n",
    "plt.xlabel(\"Metrics\")\n",
    "plt.ylabel('score')\n",
    "plt.title(\"Over all weighted scores\")\n",
    "  \n",
    "plt.xticks(ind+width,['Precision', 'Recall', 'F1-score'])\n",
    "plt.legend( tuple(f), tuple(results.keys()), loc='upper center', ncol=7)\n",
    "plt.show()\n",
    "plt.savefig('all_.png',bbox_inches = 'tight')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "us_airline_sentiment_analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
